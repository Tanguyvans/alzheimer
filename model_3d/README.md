# 3D CNN Models for Alzheimer's Disease Detection

Deep learning pipeline using DenseNet3D with CLIP pretraining for AD/CN/MCI classification from skull-stripped brain MRI scans.

## ğŸ“ Project Structure

```text
model_3d/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ TRAINING_GUIDE.md           # Detailed training guide
â”‚
â”œâ”€â”€ training/                    # Training scripts
â”‚   â””â”€â”€ train_densenet3d_clip.py  # Main training script (PyTorch Lightning)
â”‚
â”œâ”€â”€ inference/                   # Prediction scripts
â”‚   â”œâ”€â”€ predict.py               # Single file prediction
â”‚   â”œâ”€â”€ predict_batch.py         # Batch prediction (AD/CN folders)
â”‚   â””â”€â”€ predict_organized.py     # MCI progression prediction
â”‚
â”œâ”€â”€ configs/                     # Configuration files
â”‚   â””â”€â”€ training_config.yaml     # Training hyperparameters
â”‚
â”œâ”€â”€ utils/                       # Utility scripts
â”‚   â””â”€â”€ prepare_training_data.py  # Create training CSV from NIfTI files
â”‚
â”œâ”€â”€ data/                        # Training data (CSV files)
â”‚   â””â”€â”€ (generated by prepare_training_data.py)
â”‚
â””â”€â”€ outputs/                     # Training outputs
    â””â”€â”€ training/
        â”œâ”€â”€ checkpoints/         # Model checkpoints
        â””â”€â”€ tensorboard_logs/    # TensorBoard logs
```

## ğŸš€ Quick Start

### 1. Prerequisites

```bash
# Install dependencies
pip install pytorch-lightning tensorboard nibabel scipy pyyaml

# Clone ADNI unimodal models repository (required)
cd /Users/tanguyvans/Desktop/umons/alzheimer
git clone https://github.com/othmane42/ADNI_unimodal_models.git
```

### 2. Prepare Your Data

Create a CSV file with paths to your skull-stripped NIfTI files:

```bash
# From project root
python model_3d/utils/prepare_training_data.py \
  --input /Volumes/KINGSTON/ADNI-skull \
  --output model_3d/data/adni_training.csv
```

This creates a CSV with columns:
- `nii_path`: Path to .nii.gz file
- `Subject`: Patient ID
- `Group`: Diagnosis (AD, CN, MCI)
- `RID`, `visit`, `file_name`

### 3. Train the Model

```bash
# CPU training
python model_3d/training/train_densenet3d_clip.py \
  --data model_3d/data/adni_training.csv \
  --batch-size 8 \
  --epochs 50

# GPU training
python model_3d/training/train_densenet3d_clip.py \
  --data model_3d/data/adni_training.csv \
  --batch-size 16 \
  --epochs 50 \
  --gpus 1
```

### 4. Monitor Training

```bash
tensorboard --logdir model_3d/outputs/training/tensorboard_logs
```

Open http://localhost:6006 to view training progress.

### 5. Run Predictions

```bash
# Single file
python model_3d/inference/predict.py \
  --model model_3d/outputs/training/checkpoints/best.ckpt \
  --data /path/to/scan.nii.gz

# Batch prediction
python model_3d/inference/predict_batch.py \
  --input /Volumes/KINGSTON/ADNI-skull \
  --model model_3d/outputs/training/checkpoints/best.ckpt \
  --output predictions.csv
```

## ğŸ“Š Model Architecture

- **Backbone**: DenseNet3D (3D Dense Convolutional Network)
- **Pretraining**: CLIP-based initialization
- **Input**: Skull-stripped T1-weighted MRI (NIfTI format)
- **Output**: 3-class classification (AD, CN, MCI)
- **Framework**: PyTorch Lightning

### Key Features

âœ… **Patient-aware splitting** - Prevents data leakage between train/val/test
âœ… **Class balancing** - Weighted sampling handles class imbalance
âœ… **Early stopping** - Prevents overfitting
âœ… **Learning rate scheduling** - ReduceLROnPlateau
âœ… **Model checkpointing** - Saves best models automatically
âœ… **Comprehensive metrics** - Accuracy, F1, precision, recall, confusion matrix

## ğŸ“‹ Training Configuration

Edit `configs/training_config.yaml` to customize:

```yaml
training:
  batch_size: 8          # Adjust based on GPU memory
  learning_rate: 0.0001
  weight_decay: 0.00001
  max_epochs: 50
  num_workers: 4
  seed: 42

model:
  freeze_encoder: false  # true = fine-tune classifier only
  hidden_dim: 0          # 0 = direct classification
  dropout_rate: 0.0
```

## ğŸ”§ Common Commands

### Data Preparation

```bash
# Standard AD/CN/MCI folders
python model_3d/utils/prepare_training_data.py \
  --input /Volumes/KINGSTON/ADNI-skull \
  --output model_3d/data/adni_train.csv

# Organized MCI progression folders
python model_3d/utils/prepare_training_data.py \
  --input /Volumes/KINGSTON/ADNI-MCI-organized \
  --output model_3d/data/adni_mci.csv \
  --organized

# Skip validation (faster)
python model_3d/utils/prepare_training_data.py \
  --input /Volumes/KINGSTON/ADNI-skull \
  --output model_3d/data/adni_train.csv \
  --no-validate
```

### Training

```bash
# Basic training
python model_3d/training/train_densenet3d_clip.py \
  --data model_3d/data/adni_train.csv \
  --epochs 50

# Custom configuration
python model_3d/training/train_densenet3d_clip.py \
  --data model_3d/data/adni_train.csv \
  --config my_config.yaml \
  --batch-size 16 \
  --lr 0.0001 \
  --epochs 100 \
  --gpus 1

# Resume from checkpoint
python model_3d/training/train_densenet3d_clip.py \
  --data model_3d/data/adni_train.csv \
  --resume model_3d/outputs/training/checkpoints/last.ckpt \
  --gpus 1

# Freeze encoder (fine-tune classifier only)
python model_3d/training/train_densenet3d_clip.py \
  --data model_3d/data/adni_train.csv \
  --freeze-encoder \
  --epochs 20
```

### Inference

```bash
# Single prediction
python model_3d/inference/predict.py \
  --model model_3d/outputs/training/checkpoints/best.ckpt \
  --data /path/to/scan.nii.gz

# Batch prediction from folders
python model_3d/inference/predict_batch.py \
  --input /Volumes/KINGSTON/ADNI-skull \
  --model model_3d/outputs/training/checkpoints/best.ckpt \
  --output results.csv

# MCI progression prediction
python model_3d/inference/predict_organized.py \
  --input /Volumes/KINGSTON/ADNI-MCI-organized \
  --model model_3d/outputs/training/checkpoints/best.ckpt \
  --output mci_predictions.csv
```

## ğŸ“ˆ Expected Performance

With proper training on ADNI skull-stripped data:

- **AD vs CN**: ~85-90% accuracy
- **3-class (AD/CN/MCI)**: ~75-85% accuracy
- **MCI progression**: ~70-80% accuracy

Performance depends on:
- Data quality (skull-stripping, registration)
- Dataset size and balance
- Training hyperparameters
- Data augmentation

## ğŸ› Troubleshooting

### "CUDA out of memory"

```bash
# Reduce batch size
python model_3d/training/train_densenet3d_clip.py \
  --data model_3d/data/adni_train.csv \
  --batch-size 2 \
  --gpus 1
```

### "No module named 'encoders'"

```bash
# Ensure ADNI_unimodal_models is cloned at project root
cd /Users/tanguyvans/Desktop/umons/alzheimer
git clone https://github.com/othmane42/ADNI_unimodal_models.git
```

### "Invalid NIfTI file"

Check file is properly preprocessed:
```bash
python -c "import nibabel as nib; nii = nib.load('scan.nii.gz'); print(nii.shape)"
```

Files should be:
- âœ… Skull-stripped (brain only)
- âœ… MNI-registered
- âœ… 3D volumes (not 4D)
- âœ… Reasonable dimensions (~128Â³ or similar)

### Low validation accuracy

1. Check data quality and labels
2. Increase training epochs
3. Try different learning rates
4. Add data augmentation
5. Verify patient-aware split (no leakage)

## ğŸ“š Documentation

- **[TRAINING_GUIDE.md](TRAINING_GUIDE.md)** - Comprehensive training guide with advanced topics
- **[training_config.yaml](configs/training_config.yaml)** - Configuration file reference
- **[ADNI_unimodal_models](../ADNI_unimodal_models/)** - Model architecture documentation

## ğŸ”— Related Components

### Preprocessing Pipeline

See [`preprocessing/`](../preprocessing/) for MRI preprocessing:
1. DICOM â†’ NIfTI conversion
2. N4 bias correction
3. MNI registration
4. Skull stripping (SynthStrip)

### Tabular Models

See [`tabular/`](../tabular/) for XGBoost-based classification using clinical features.

### Dataset Documentation

See [`docs/datasets/`](../docs/datasets/) for dataset information and analysis.

## ğŸ¯ Complete End-to-End Workflow

### From Raw DICOM to Trained Model

#### Step 1: Clean Raw DICOM Scans

If you have raw DICOM files, use the **[data cleaning pipeline](../data_cleaning/)** to create training-ready NIfTI files.

**Complete 3-step pipeline:**

```bash
# 1. DICOM â†’ NIfTI (MPRAGE sequences only)
cd data_cleaning/01_dicom_conversion
python convert_adni.py

# 2. N4 Bias Correction + MNI Registration
cd ../02_registration
python run_registration_batch.py

# 3. Skull Stripping (SynthStrip)
cd ../03_skull_stripping
python run_skull_strip_registered.py
```

**Output**: `/Volumes/KINGSTON/ADNI-skull/` contains skull-stripped `.nii.gz` files.

**Features:**
- âœ… Automatic progress tracking with JSON logs
- âœ… Resume support (`--resume` flag)
- âœ… ~3-4 minutes per scan processing time
- âœ… Graceful interruption (Ctrl+C)

See [`data_cleaning/README.md`](../data_cleaning/README.md) for detailed documentation.

#### Step 2: Organize Data by Diagnosis

Organize preprocessed files into AD/CN/MCI folders:

```bash
# Create organized structure
mkdir -p ADNI-skull/{AD,CN,MCI}

# Move files based on diagnosis (manual or scripted)
# Structure should be:
# ADNI-skull/
# â”œâ”€â”€ AD/
# â”‚   â”œâ”€â”€ patient1_scan.nii.gz
# â”‚   â””â”€â”€ patient2_scan.nii.gz
# â”œâ”€â”€ CN/
# â”‚   â””â”€â”€ ...
# â””â”€â”€ MCI/
#     â””â”€â”€ ...
```

#### Step 3: Prepare Training CSV

Create a CSV file with paths to all skull-stripped files:

```bash
python model_3d/utils/prepare_training_data.py \
  --input /Volumes/KINGSTON/ADNI-skull \
  --output model_3d/data/training.csv
```

**Output**: CSV with columns: `nii_path`, `Subject`, `Group`, `RID`, `visit`

#### Step 4: Train the Model

```bash
# GPU training (recommended)
python model_3d/training/train_densenet3d_clip.py \
  --data model_3d/data/training.csv \
  --batch-size 16 \
  --epochs 50 \
  --lr 0.0001 \
  --gpus 1

# CPU training (slower)
python model_3d/training/train_densenet3d_clip.py \
  --data model_3d/data/training.csv \
  --batch-size 8 \
  --epochs 50
```

#### Step 5: Monitor Training Progress

```bash
# Start TensorBoard
tensorboard --logdir model_3d/outputs/training/tensorboard_logs

# Open browser to http://localhost:6006
```

Monitor:
- Training/validation loss curves
- Accuracy metrics (train/val/test)
- Confusion matrices
- Learning rate schedule

#### Step 6: Run Predictions

```bash
# Predict on new scans
python model_3d/inference/predict_batch.py \
  --input /path/to/test/scans \
  --model model_3d/outputs/training/checkpoints/best.ckpt \
  --output predictions.csv
```

**Output**: CSV with predictions and probabilities for each scan.

## ğŸ“„ Citation

If you use this pipeline, please cite:

- **ADNI Dataset**: http://adni.loni.usc.edu/
- **DenseNet**: Huang et al., "Densely Connected Convolutional Networks", CVPR 2017
- **CLIP**: Radford et al., "Learning Transferable Visual Models From Natural Language Supervision", ICML 2021

## ğŸ“ Support

For issues:
1. Check [TRAINING_GUIDE.md](TRAINING_GUIDE.md) troubleshooting section
2. Verify data preparation output
3. Review TensorBoard logs
4. Check GPU memory usage

## ğŸ”„ Updates

- **2025-10**: Initial release with DenseNet3D + CLIP training pipeline
