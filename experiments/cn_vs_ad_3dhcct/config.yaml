# Configuration for CN vs AD with 3D HCCT Model
#
# This experiment uses the 3D Hybrid Compact Convolutional Transformers (3D HCCT)
# architecture from: https://github.com/arindammajee/Alzheimer-Detection-with-3D-HCCT
#
# Paper: "Enhancing MRI-Based Classification of Alzheimer's Disease with
#         Explainable 3D Hybrid Compact Convolutional Transformers"
#
# Usage:
#   Step 1: Use existing splits from cn_vs_ad_baseline (or create new ones)
#   Step 2: python train.py --config config.yaml

# =============================================================================
# DATA PATHS
# =============================================================================
data:
  # Use the same splits as baseline experiment
  train_csv: "../cn_vs_ad_baseline/data/splits/train.csv"
  val_csv: "../cn_vs_ad_baseline/data/splits/val.csv"
  test_csv: "../cn_vs_ad_baseline/data/splits/test.csv"

  # Output paths (relative to this experiment folder)
  checkpoints_dir: "checkpoints"
  logs_dir: "logs"
  results_dir: "results"

# =============================================================================
# MODEL ARCHITECTURE - 3D HCCT
# =============================================================================
model:
  name: "3D_HCCT"

  # Image/volume configuration
  image_size: 192              # Input volume size (192x192x192)
  patch_size: 16               # Patch size for ViT (not used in conv-based embedding)
  num_channels: 1              # Number of input channels (grayscale MRI)
  num_classes: 2               # Binary classification (CN vs AD)

  # Vision Transformer configuration
  hidden_size: 512             # Hidden dimension size
  num_hidden_layers: 3         # Number of transformer blocks
  num_attention_heads: 8       # Number of attention heads
  intermediate_size: 2048      # MLP intermediate size (typically 4x hidden_size)

  # Regularization
  hidden_dropout_prob: 0.1     # Dropout probability
  attention_probs_dropout_prob: 0.1  # Attention dropout

  # Other settings
  qkv_bias: true               # Use bias in QKV projections
  use_faster_attention: true   # Use optimized attention implementation
  initializer_range: 0.02      # Weight initialization range

# =============================================================================
# TRAINING HYPERPARAMETERS
# =============================================================================
training:
  batch_size: 4                # Reduced batch size for 192^3 volumes (memory intensive)
  epochs: 100                  # Maximum number of epochs
  learning_rate: 0.0001        # Initial learning rate (1e-4)
  weight_decay: 0.01           # Weight decay for AdamW
  optimizer: "AdamW"           # Optimizer: Adam or AdamW

  # Learning rate scheduler
  scheduler: "ReduceLROnPlateau"  # Options: ReduceLROnPlateau, CosineAnnealing, None
  lr_patience: 5               # Reduce LR after N epochs without improvement
  lr_factor: 0.5               # Multiply LR by this factor

  # Class balancing
  use_weighted_loss: true      # Use weighted cross-entropy for class imbalance
  use_weighted_sampling: false # Use weighted random sampler (alternative to weighted loss)

  # Reproducibility
  seed: 42                     # Random seed

# =============================================================================
# DATA AUGMENTATION
# =============================================================================
augmentation:
  enabled: false               # Enable data augmentation
  random_flip_prob: 0.5        # Probability of random flip
  random_rotation_degrees: 15  # Max rotation degrees
  random_affine: true          # Apply random affine transforms

# =============================================================================
# HARDWARE & PERFORMANCE
# =============================================================================
hardware:
  device: "cuda"               # cuda or cpu
  num_workers: 4               # Number of dataloader workers
  pin_memory: true             # Pin memory for faster GPU transfer
  mixed_precision: false       # Use automatic mixed precision (FP16)

# =============================================================================
# CALLBACKS & MONITORING
# =============================================================================
callbacks:
  early_stopping:
    enabled: true
    patience: 20               # Stop if no improvement after N epochs
    monitor: "val_loss"        # Metric to monitor
    mode: "min"                # Minimize or maximize

  checkpoint:
    save_top_k: 3              # Save top K checkpoints
    monitor: "val_accuracy"    # Metric to monitor for best checkpoint
    mode: "max"                # Minimize or maximize
    save_last: true            # Always save last checkpoint

  logging:
    log_every_n_steps: 10      # Log metrics every N steps
    save_training_plot: true   # Save training curves

# =============================================================================
# WEIGHTS & BIASES (WANDB) LOGGING
# =============================================================================
wandb:
  enabled: true                # Enable/disable wandb logging
  project: "alzheimer-research"
  entity: null                 # Wandb entity/team name (null = use default)
  run_name: "cn-ad-3dhcct"     # Custom run name
  log_model: false             # Upload model checkpoints to wandb
  tags:
    - 3d-hcct
    - vision-transformer
    - hybrid-cnn-transformer
    - cn-ad-classification
  notes: "3D Hybrid Compact Convolutional Transformers for AD classification"

# =============================================================================
# EVALUATION
# =============================================================================
evaluation:
  metrics:
    - accuracy
    - balanced_accuracy
    - precision
    - recall
    - f1
    - auc
    - confusion_matrix

  save_predictions: true       # Save predictions on test set
  save_attention_maps: false   # Save attention visualizations (memory intensive)
