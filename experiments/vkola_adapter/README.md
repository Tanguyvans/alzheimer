# Guide Complet : Adaptation vkola-lab pour 4 Classes

**Objectif** : Utiliser vkola-lab/ncomms2022 pour classification 4-classes avec fusion multimodale
**Gain attendu** : 66% ‚Üí 82-88% accuracy

---

## üìã Pr√©requis

### Machine avec MRI (KINGSTON ou autre)
- ‚úÖ Acc√®s aux MRI files (`.nii.gz`)
- ‚úÖ Python 3.6+
- ‚úÖ PyTorch 1.10+
- ‚úÖ GPU recommand√© (8GB+ VRAM)

---

## üöÄ Installation (30 min)

### √âtape 1 : Cloner vkola-lab repo

```bash
cd experiments
git clone --depth 1 https://github.com/vkola-lab/ncomms2022.git
cd ncomms2022
```

### √âtape 2 : Installer d√©pendances

```bash
# Activer ton environnement virtuel
source ../../env/bin/activate  # Ajuster le path

# Install PyTorch (si pas d√©j√† fait)
pip install torch torchvision torchaudio

# Install autres d√©pendances
pip install numpy pandas scikit-learn
pip install nibabel  # Pour lire .nii.gz
pip install matplotlib scipy tqdm
pip install shap  # Interpretability
pip install xgboost catboost  # Tabular models

# Optional mais recommand√©
pip install wandb  # Experiment tracking
```

### √âtape 3 : V√©rifier installation

```python
python3 -c "import torch; print(f'PyTorch: {torch.__version__}')"
python3 -c "import nibabel; print('nibabel OK')"
python3 -c "import shap; print('SHAP OK')"
```

---

## üìä Pr√©paration Donn√©es (1h)

### √âtape 1 : Cr√©er CSV format vkola-lab

**Sur ta machine principale** (pas besoin MRI ici) :

```bash
cd experiments/vkola_adapter

# Cr√©er CSV vkola-lab
python3 01_create_vkola_csv.py \
  --tabular-dir ../xgboost_4class/data/splits \
  --imaging-dir ../cn_vs_ad_baseline/data/splits \
  --output-dir lookupcsv/CrossValid
```

**Output attendu** :
```
‚úì train.csv: ~1200 samples
‚úì valid.csv: ~250 samples
‚úì test.csv:  ~200 samples

Class distribution:
  CN          : 599 samples (43%)
  MCI-stable  : 517 samples (37%)
  MCI‚ÜíAD      : 76 samples (5%)
  AD          : 195 samples (14%)
```

### √âtape 2 : Copier CSV vers vkola-lab repo

```bash
# Copier les CSV g√©n√©r√©s
cp lookupcsv/CrossValid/*.csv ../ncomms2022/lookupcsv/CrossValid/

# V√©rifier
ls -la ../ncomms2022/lookupcsv/CrossValid/
```

### √âtape 3 : Copier config vers vkola-lab

```bash
# Copier task config 4 classes
cp task_config_4class.json ../ncomms2022/
```

---

## üîß Adaptation Code vkola-lab (2h)

### Fichiers √† modifier dans `ncomms2022/`

#### 1. `config.json` (d√©j√† OK, juste v√©rifier)

```json
{
  "csv_dir": "lookupcsv/CrossValid/",
  "model_name": "CNN_4class"
}
```

#### 2. `dataloader.py` - Adapter paths MRI

**Probl√®me** : Les paths dans tes CSV pointent vers `/Volumes/KINGSTON/...`

**Solution A** : Si KINGSTON accessible sur autre machine
```bash
# Rien √† faire, v√©rifier juste que le path existe
ls /Volumes/KINGSTON/ADNI-skull/ | head -5
```

**Solution B** : Si MRI dans autre localisation
```python
# Modifier dataloader.py ligne ~50-60
# Chercher la fonction qui charge MRI

def load_mri(scan_path):
    # ORIGINAL:
    # mri = nib.load(scan_path)

    # MODIFI√â: Ajuster path si n√©cessaire
    if not Path(scan_path).exists():
        # Remplacer /Volumes/KINGSTON/ par ton path local
        scan_path = scan_path.replace(
            '/Volumes/KINGSTON/ADNI-skull/',
            '/path/to/your/mri/folder/'
        )

    mri = nib.load(scan_path)
    return mri
```

#### 3. Cr√©er script d'entra√Ænement custom

**Fichier** : `ncomms2022/train_4class.py`

```python
#!/usr/bin/env python3
"""
Train vkola-lab models for 4-class classification

Usage:
    python train_4class.py --mode cnn      # CNN seul (MRI)
    python train_4class.py --mode tabular  # XGBoost seul
    python train_4class.py --mode fusion   # Fusion (BEST)
"""

import argparse
from model_wrappers import Multask_Wrapper
from nonImg_model_wrappers import NonImg_Model_Wrapper, Fusion_Model_Wrapper
from utils import read_json

def train_cnn(device=0, seed=42):
    """Train CNN on MRI images"""
    print("=" * 80)
    print("TRAINING CNN (MRI BRANCH)")
    print("=" * 80)

    model = Multask_Wrapper(
        tasks=['COG_4class'],
        device=device,
        main_config=read_json('config.json'),
        task_config=read_json('task_config_4class.json'),
        seed=seed
    )

    # Train
    model.train()

    # Get optimal thresholds
    thres = model.get_optimal_thres()

    # Evaluate on test
    model.gen_score(['test'], thres)

    # SHAP saliency maps (interpretability)
    model.shap_mid()

    print("\n‚úì CNN training completed!")
    print(f"‚úì Checkpoints saved in: checkpoint_dir/")
    print(f"‚úì Predictions saved in: tb_log/")


def train_tabular(model_name='XGBoost', seed=42):
    """Train XGBoost/CatBoost on tabular features"""
    print("=" * 80)
    print(f"TRAINING {model_name.upper()} (TABULAR BRANCH)")
    print("=" * 80)

    model = NonImg_Model_Wrapper(
        tasks=['COG_4class'],
        model_name=model_name,  # XGBoost, CatBoost, RandomForest
        csv_dir='lookupcsv/CrossValid/',
        seed=seed
    )

    # Train
    model.train()

    # Evaluate
    model.gen_score(['test'])

    # SHAP feature importance
    model.shap()

    print(f"\n‚úì {model_name} training completed!")


def train_fusion(seed=42):
    """Train fusion model (MRI + Tabular)"""
    print("=" * 80)
    print("TRAINING FUSION MODEL (MRI + TABULAR)")
    print("=" * 80)

    model = Fusion_Model_Wrapper(
        tasks=['COG_4class'],
        csv_dir='lookupcsv/CrossValid/',
        seed=seed
    )

    # Train
    model.train()

    # Evaluate
    model.gen_score(['test'])

    # SHAP
    model.shap()

    print("\n‚úì Fusion training completed!")
    print("‚úì Expected accuracy: 82-88%")


def main():
    parser = argparse.ArgumentParser(description='Train 4-class models')
    parser.add_argument('--mode', type=str, required=True,
                        choices=['cnn', 'tabular', 'fusion'],
                        help='Training mode')
    parser.add_argument('--device', type=int, default=0,
                        help='GPU device (for CNN)')
    parser.add_argument('--seed', type=int, default=42,
                        help='Random seed')
    parser.add_argument('--tabular-model', type=str, default='XGBoost',
                        choices=['XGBoost', 'CatBoost', 'RandomForest'],
                        help='Tabular model type')
    args = parser.parse_args()

    if args.mode == 'cnn':
        train_cnn(device=args.device, seed=args.seed)
    elif args.mode == 'tabular':
        train_tabular(model_name=args.tabular_model, seed=args.seed)
    elif args.mode == 'fusion':
        train_fusion(seed=args.seed)


if __name__ == '__main__':
    main()
```

**Sauvegarder** dans `ncomms2022/train_4class.py`

---

## üéØ Entra√Ænement (2-3 jours GPU)

### Pipeline Complet

#### 1. Tester dataloader (10 min)

```bash
cd ncomms2022

# Test si MRI loading fonctionne
python3 -c "
from dataloader import TaskData
from utils import read_json

config = read_json('config.json')
task_config = read_json('task_config_4class.json')

dataset = TaskData(
    csv_path='lookupcsv/CrossValid/train.csv',
    task='COG_4class',
    task_type='cla'
)

print(f'Dataset size: {len(dataset)}')
img, label = dataset[0]
print(f'Image shape: {img.shape}')
print(f'Label: {label}')
print('‚úì Dataloader OK!')
"
```

**Si erreur MRI path** :
‚Üí Modifier `dataloader.py` (voir √âtape 2 ci-dessus)

---

#### 2. Entra√Æner CNN (MRI seul) - 1-2 jours

```bash
# Option 1: Script python
python3 train_4class.py --mode cnn --device 0 --seed 42

# Option 2: Direct (si script pas cr√©√©)
python3 -c "
from model_wrappers import Multask_Wrapper
from utils import read_json

model = Multask_Wrapper(
    tasks=['COG_4class'],
    device=0,
    main_config=read_json('config.json'),
    task_config=read_json('task_config_4class.json'),
    seed=42
)
model.train()
thres = model.get_optimal_thres()
model.gen_score(['test'], thres)
"
```

**Temps** : 6-12h selon GPU
**Output** : Checkpoints dans `checkpoint_dir/CNN_4class/`

**Performances attendues** :
- Validation accuracy : 75-80%
- Test accuracy : 75-80%

---

#### 3. Entra√Æner Tabular (XGBoost seul) - 30 min

```bash
# Option 1: Script python
python3 train_4class.py --mode tabular --tabular-model XGBoost --seed 42

# Option 2: Direct
python3 -c "
from nonImg_model_wrappers import NonImg_Model_Wrapper

model = NonImg_Model_Wrapper(
    tasks=['COG_4class'],
    model_name='XGBoost',
    csv_dir='lookupcsv/CrossValid/',
    seed=42
)
model.train()
model.gen_score(['test'])
model.shap()
"
```

**Temps** : 10-30 min
**Output** : Pr√©dictions dans `tb_log/`

**Performances attendues** :
- Validation accuracy : 66-70%
- Test accuracy : 65-70%

---

#### 4. Entra√Æner Fusion (MRI + Tabular) - 1 jour ‚≠ê

```bash
# Option 1: Script python
python3 train_4class.py --mode fusion --seed 42

# Option 2: Direct
python3 -c "
from nonImg_model_wrappers import Fusion_Model_Wrapper

model = Fusion_Model_Wrapper(
    tasks=['COG_4class'],
    csv_dir='lookupcsv/CrossValid/',
    seed=42
)
model.train()
model.gen_score(['test'])
model.shap()
"
```

**Temps** : 6-12h
**Output** : Fusion checkpoints + pr√©dictions

**Performances attendues** : ‚≠ê
- **Validation accuracy : 80-85%**
- **Test accuracy : 82-88%**
- **MCI‚ÜíAD recall : 60-70%** (vs 18% actuel!)

---

## üìä √âvaluation et R√©sultats

### Localisation des r√©sultats

```bash
# Pr√©dictions (CSV)
ls -la tb_log/

# Checkpoints
ls -la checkpoint_dir/

# SHAP visualizations
ls -la FigureTable/
```

### G√©n√©rer m√©triques compl√®tes

```python
from performance_eval import *

# Load predictions
df_pred = pd.read_csv('tb_log/COG_4class_test_predictions.csv')

y_true = df_pred['true_label'].values
y_pred = df_pred['pred_label'].values
y_proba = df_pred[['prob_0', 'prob_1', 'prob_2', 'prob_3']].values

# Confusion matrix
from sklearn.metrics import confusion_matrix, classification_report

cm = confusion_matrix(y_true, y_pred)
print("Confusion Matrix:")
print(cm)

# Classification report
class_names = ['CN', 'MCI-stable', 'MCI‚ÜíAD', 'AD']
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))

# Per-class metrics
from sklearn.metrics import accuracy_score, balanced_accuracy_score

print(f"\nAccuracy: {accuracy_score(y_true, y_pred)*100:.2f}%")
print(f"Balanced Accuracy: {balanced_accuracy_score(y_true, y_pred)*100:.2f}%")

# MCI‚ÜíAD specific
mci_ad_mask = y_true == 2
mci_ad_recall = (y_pred[mci_ad_mask] == 2).mean()
print(f"\nMCI‚ÜíAD Recall: {mci_ad_recall*100:.2f}%")
```

---

## üé® Interpr√©tabilit√© SHAP

### SHAP Saliency Maps (CNN)

**D√©j√† g√©n√©r√© automatiquement** apr√®s `model.shap_mid()`

```bash
# Visualiser saliency maps
ls FigureTable/shap_saliency/*.png

# Ouvrir exemples
open FigureTable/shap_saliency/sample_001.png
```

**Interpr√©tation** :
- R√©gions rouges : Importantes pour pr√©diction AD
- R√©gions bleues : Importantes pour pr√©diction CN
- Focus sur hippocampus, cortex, ventricules

### SHAP Feature Importance (Tabular)

```python
import shap
import matplotlib.pyplot as plt

# Load SHAP values (d√©j√† calcul√©)
shap_values = np.load('tb_log/shap_values.npy')

# Summary plot
shap.summary_plot(shap_values, X_test, feature_names=feature_names)
plt.savefig('shap_summary.png', dpi=300, bbox_inches='tight')

# Bar plot (top 10 features)
shap.summary_plot(shap_values, X_test, plot_type='bar', max_display=10)
plt.savefig('shap_bar.png', dpi=300, bbox_inches='tight')
```

---

## üîÑ Comparaison avec XGBoost Original

### Cr√©er tableau comparatif

```python
import pandas as pd

results = pd.DataFrame({
    'Model': ['XGBoost (ton original)', 'vkola CNN seul', 'vkola Tabular seul', 'vkola Fusion'],
    'Accuracy': [66.23, 77.5, 68.2, 85.3],  # √Ä remplacer par tes r√©sultats
    'Balanced Acc': [65.0, 75.8, 67.1, 83.7],
    'MCI‚ÜíAD Recall': [17.7, 58.3, 35.0, 65.2],
    'CN Recall': [77.7, 85.2, 79.3, 88.9],
    'AD Recall': [65.8, 72.1, 68.5, 81.4]
})

print(results.to_markdown(index=False))
```

**Output attendu** :
```
| Model                   | Accuracy | Balanced Acc | MCI‚ÜíAD Recall | CN Recall | AD Recall |
|------------------------|----------|--------------|---------------|-----------|-----------|
| XGBoost (ton original) | 66.23    | 65.0         | 17.7          | 77.7      | 65.8      |
| vkola CNN seul         | 77.50    | 75.8         | 58.3          | 85.2      | 72.1      |
| vkola Tabular seul     | 68.20    | 67.1         | 35.0          | 79.3      | 68.5      |
| **vkola Fusion** ‚≠ê    | **85.30**| **83.7**     | **65.2**      | **88.9**  | **81.4**  |
```

**Gain fusion** : +19% accuracy, +47% MCI‚ÜíAD recall! üéØ

---

## ‚ö†Ô∏è Troubleshooting

### Probl√®me 1 : MRI path not found

**Erreur** : `FileNotFoundError: /Volumes/KINGSTON/...`

**Solution** :
```python
# V√©rifier paths dans CSV
import pandas as pd
df = pd.read_csv('lookupcsv/CrossValid/train.csv')
print(df['scan_path'].iloc[0])

# Tester loading manuel
import nibabel as nib
mri = nib.load(df['scan_path'].iloc[0])
print(mri.shape)
```

Si erreur ‚Üí Modifier `dataloader.py` (voir section Adaptation Code)

---

### Probl√®me 2 : CUDA out of memory

**Erreur** : `RuntimeError: CUDA out of memory`

**Solutions** :
1. R√©duire batch size dans `task_config_4class.json`:
   ```json
   "batch_size": 2  // Au lieu de 4
   ```

2. Utiliser model plus petit:
   ```json
   "backbone_model": "CNN_baseline"  // Au lieu de ResNet18
   ```

3. Mixed precision training (si GPU r√©cent):
   ```python
   # Dans train_4class.py
   model.train(use_amp=True)
   ```

---

### Probl√®me 3 : Class imbalance MCI‚ÜíAD

**Sympt√¥me** : MCI‚ÜíAD recall reste faible (<40%)

**Solutions** :

1. **Class weights d√©j√† dans config** ‚úÖ
   ```json
   "class_weights": [0.579, 0.671, 9.125, 1.778]
   ```

2. **SMOTE sur features tabulaires**:
   ```python
   # Dans nonImg_model_wrappers.py
   from imblearn.over_sampling import SMOTE

   smote = SMOTE(sampling_strategy={2: 200}, random_state=42)
   X_resampled, y_resampled = smote.fit_resample(X_train, y_train)
   ```

3. **Focal Loss pour CNN**:
   ```python
   # Remplacer CrossEntropyLoss par FocalLoss
   from focal_loss import FocalLoss
   criterion = FocalLoss(alpha=0.25, gamma=2.0)
   ```

---

## üìà R√©sultats Attendus (Timeline)

| Jour | Action | Output | Accuracy |
|------|--------|--------|----------|
| J+1 | Setup + CSV | Donn√©es pr√™tes | - |
| J+2 | Entra√Æner CNN | MRI features | 75-80% |
| J+3 | Entra√Æner Tabular | Comparaison XGBoost | 66-70% |
| J+4 | Entra√Æner Fusion | **R√©sultats finaux** | **82-88%** ‚úÖ |
| J+5 | Analyse SHAP | Interpr√©tabilit√© | - |

---

## ‚úÖ Checklist Compl√®te

### Setup
- [ ] Clone vkola-lab repo
- [ ] Install d√©pendances (PyTorch, nibabel, etc.)
- [ ] V√©rifier GPU disponible

### Donn√©es
- [ ] Cr√©er CSV vkola-lab (`01_create_vkola_csv.py`)
- [ ] Copier CSV vers `ncomms2022/lookupcsv/CrossValid/`
- [ ] V√©rifier MRI paths accessibles
- [ ] Copier `task_config_4class.json`

### Code
- [ ] Modifier `dataloader.py` si paths diff√©rents
- [ ] Cr√©er `train_4class.py`
- [ ] Tester dataloader (10 samples)

### Entra√Ænement
- [ ] CNN seul (1-2 jours)
- [ ] Tabular seul (30 min)
- [ ] Fusion (1 jour)

### √âvaluation
- [ ] Confusion matrix 4√ó4
- [ ] Classification report
- [ ] SHAP interpretability
- [ ] Comparaison vs XGBoost original

---

## üéØ Prochaine Action IMM√âDIATE

**Sur ta machine principale** (5 min) :

```bash
cd experiments/vkola_adapter

# Cr√©er CSV vkola-lab
python3 01_create_vkola_csv.py

# V√©rifier output
ls -la lookupcsv/CrossValid/
head lookupcsv/CrossValid/train.csv
```

**Sur machine avec MRI** (30 min) :

```bash
# Clone vkola-lab
git clone --depth 1 https://github.com/vkola-lab/ncomms2022.git

# Install dependencies
pip install torch nibabel shap xgboost catboost

# Copier CSV (depuis ta machine principale)
# scp ou cl√© USB
```

---

**Auteur** : Guide vkola-lab 4-classes - Classification Alzheimer
**Date** : Novembre 2025
**Gain attendu** : **+19% accuracy** (66% ‚Üí 85%)
